{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "VXQR_t0pCbj0",
        "outputId": "63d53390-2d5b-4153-9670-1a93763b893a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "3e09d213a4a643368f41f96f177a6fba",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.24.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Installing collected packages: gensim\n",
            "Successfully installed gensim-4.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip uninstall gensim -y\n",
        "!pip install numpy==1.24.3\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2DyPw9TAL3f",
        "outputId": "9de9935b-1c3b-4182-fd26-ce053c8ff62e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.24.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import libraries\n",
        "!pip install numpy\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from nltk.corpus import conll2000, brown, treebank\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nltk.download('conll2000')\n",
        "nltk.download('brown')\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_P0N61aAQl5"
      },
      "outputs": [],
      "source": [
        "# loading 3 nltk libraries\n",
        "tagged_sents = (\n",
        "    conll2000.tagged_sents(tagset='universal') +\n",
        "    brown.tagged_sents(tagset='universal') +\n",
        "    treebank.tagged_sents(tagset='universal')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaGVOkKnATeY"
      },
      "outputs": [],
      "source": [
        "# making tag list and word vocabulary\n",
        "word_to_ix = {}\n",
        "tag_to_ix = {}\n",
        "\n",
        "for sent in tagged_sents:\n",
        "    for word, tag in sent:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n",
        "\n",
        "ix_to_tag = {i: t for t, i in tag_to_ix.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT1pUP9vAWv8",
        "outputId": "857a1916-70c8-45fb-db56-838b5ac84570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# loading gloves embedding for embedding size\n",
        "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.random.normal(scale=0.6, size=(len(word_to_ix), embedding_dim))\n",
        "for word, idx in word_to_ix.items():\n",
        "    if word in glove_model:\n",
        "        embedding_matrix[idx] = glove_model[word]\n",
        "\n",
        "pretrained_embeddings = torch.tensor(embedding_matrix, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLHqKOxhAYhC"
      },
      "outputs": [],
      "source": [
        "# data train test split\n",
        "data = [\n",
        "    ([word.lower() for word, tag in sent], [tag for word, tag in sent])\n",
        "    for sent in tagged_sents\n",
        "]\n",
        "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL32l7EJAZx1"
      },
      "outputs": [],
      "source": [
        "# model definition\n",
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, pretrained_embeddings):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(pretrained_embeddings)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.dropout(self.embedding(sentence))\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        tag_space = self.fc(lstm_out.view(len(sentence), -1))\n",
        "        return tag_space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT0WO3KCAbQj"
      },
      "outputs": [],
      "source": [
        "# model training\n",
        "hidden_dim = 64\n",
        "model = BiLSTMTagger(len(word_to_ix), len(tag_to_ix), embedding_dim, hidden_dim, pretrained_embeddings)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    return torch.tensor([to_ix[w] for w in seq], dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W-HVmCUAc8m",
        "outputId": "b4d10f56-3dd7-4488-a0c7-1f093a5bc225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Loss = 28164.05\n",
            "Epoch 2: Loss = 24883.98\n",
            "Epoch 3: Loss = 24004.04\n",
            "Epoch 4: Loss = 23341.24\n",
            "Epoch 5: Loss = 22897.83\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for words, tags in train_data:\n",
        "        if any(w not in word_to_ix or t not in tag_to_ix for w, t in zip(words, tags)):\n",
        "            continue\n",
        "        model.zero_grad()\n",
        "        inputs = prepare_sequence(words, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HfyDGdqXAepn",
        "outputId": "1df2a8ed-2e42-42c4-df60-a940a8dccedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS Tagging Accuracy: 0.9313\n"
          ]
        }
      ],
      "source": [
        "# model evaluation\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for words, tags in test_data:\n",
        "        if any(w not in word_to_ix or t not in tag_to_ix for w, t in zip(words, tags)):\n",
        "            continue\n",
        "        inputs = prepare_sequence(words, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        outputs = model(inputs)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_pred.extend(predictions.tolist())\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"POS Tagging Accuracy: {accuracy:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}